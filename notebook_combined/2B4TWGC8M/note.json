{"paragraphs":[{"text":"%md\n## Magellan: Geospatial Analytics on Spark\nBy [Ram Sriharsha](http://hortonworks.com/blog/author/rsriharsha/)\n\n#### Pre-requisistes\nThis notebook requires Spark 1.4.1\n\n#### Introduction\nGeospatial data is pervasive—in mobile devices, sensors, logs, and wearables. This data’s spatial context is an important variable in many predictive analytics applications.\n\nTo benefit from spatial context in a predictive analytics application, we need to be able to parse geospatial datasets at scale, join them with target datasets that contain point in space information, and answer geometrical queries efficiently.\n\nUnfortunately, if you are working with geospatial data and big data sets that need spatial context, there are limited open source tools that make it easy for you to parse and efficiently query spatial datasets at scale. This poses significant challenges for leveraging geospatial data in business intelligence and predictive analytics applications.\n\nThis is the problem that [Magellan](https://github.com/harsha2010/magellan) sets out to solve. Magellan is an open source library for Geospatial Analytics that uses [Apache Spark](http://spark.apache.org/) as the underlying execution engine. Magellan facilitates geospatial queries and builds upon Spark to solve hard problems of dealing with geospatial data at scale.\n\nIn this notebook, we will introduce the problem of geospatial analytics and show how Magellan allows users to ingest geospatial data and run spatial queries at scale.\n\nTo do so, we will analyze the problem of using Uber data to examine the flow of uber traffic in the city of San Francisco.","dateUpdated":"2015-10-25T02:32:33+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","tableHide":false,"editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763066523_1596045350","id":"20151025-015106_840181723","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Magellan: Geospatial Analytics on Spark</h2>\n<p>By <a href=\"http://hortonworks.com/blog/author/rsriharsha/\">Ram Sriharsha</a></p>\n<h4>Pre-requisistes</h4>\n<p>This notebook requires Spark 1.4.1</p>\n<h4>Introduction</h4>\n<p>Geospatial data is pervasive—in mobile devices, sensors, logs, and wearables. This data’s spatial context is an important variable in many predictive analytics applications.</p>\n<p>To benefit from spatial context in a predictive analytics application, we need to be able to parse geospatial datasets at scale, join them with target datasets that contain point in space information, and answer geometrical queries efficiently.</p>\n<p>Unfortunately, if you are working with geospatial data and big data sets that need spatial context, there are limited open source tools that make it easy for you to parse and efficiently query spatial datasets at scale. This poses significant challenges for leveraging geospatial data in business intelligence and predictive analytics applications.</p>\n<p>This is the problem that <a href=\"https://github.com/harsha2010/magellan\">Magellan</a> sets out to solve. Magellan is an open source library for Geospatial Analytics that uses <a href=\"http://spark.apache.org/\">Apache Spark</a> as the underlying execution engine. Magellan facilitates geospatial queries and builds upon Spark to solve hard problems of dealing with geospatial data at scale.</p>\n<p>In this notebook, we will introduce the problem of geospatial analytics and show how Magellan allows users to ingest geospatial data and run spatial queries at scale.</p>\n<p>To do so, we will analyze the problem of using Uber data to examine the flow of uber traffic in the city of San Francisco.</p>\n"},"dateCreated":"2015-10-25T01:51:06+0000","dateStarted":"2015-10-25T02:32:33+0000","dateFinished":"2015-10-25T02:32:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:187"},{"text":"%md\n#### Mapping the flow of Uber traffic in San Francisco with Magellan\nUber has published a dataset of GPS coordinates of [all trips within San Francisco](https://raw.githubusercontent.com/dima42/uber-gps-analysis/master/gpsdata/all.tsv).\n\nOur goal in this example is to join the Uber dataset with the [San Francisco neighborhoods dataset](http://www.arcgis.com/home/item.html?id=3b2a461c2c7848899b7b4cbfa9ebdb67)) to obtain some interesting insights into the patterns of Uber trips in San Francisco.\n\nMagellan has both Scala and Python bindings. In this blog post we use  the Scala APIs.\nMagellan is a Spark Package, and can be included into Zeppelin as below:","dateUpdated":"2015-10-25T02:11:15+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763221863_-1140290472","id":"20151025-015341_1752661711","result":{"code":"SUCCESS","type":"HTML","msg":"<h4>Mapping the flow of Uber traffic in San Francisco with Magellan</h4>\n<p>Uber has published a dataset of GPS coordinates of <a href=\"https://raw.githubusercontent.com/dima42/uber-gps-analysis/master/gpsdata/all.tsv\">all trips within San Francisco</a>.</p>\n<p>Our goal in this example is to join the Uber dataset with the <a href=\"http://www.arcgis.com/home/item.html?id=3b2a461c2c7848899b7b4cbfa9ebdb67\">San Francisco neighborhoods dataset</a>) to obtain some interesting insights into the patterns of Uber trips in San Francisco.</p>\n<p>Magellan has both Scala and Python bindings. In this blog post we use  the Scala APIs.\n<br  />Magellan is a Spark Package, and can be included into Zeppelin as below:</p>\n"},"dateCreated":"2015-10-25T01:53:41+0000","dateStarted":"2015-10-25T02:11:16+0000","dateFinished":"2015-10-25T02:11:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:188"},{"title":"Import Magellan from maven","text":"%dep\nz.addRepo(\"Spark Packages Repo\").url(\"http://dl.bintray.com/spark-packages/maven\")\nz.load(\"com.esri.geometry:esri-geometry-api:1.2.1\")\nz.load(\"harsha2010:magellan:1.0.3-s_2.10\")","dateUpdated":"2015-10-25T02:11:16+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445761734505_353006497","id":"20151025-012854_1186772690","result":{"code":"SUCCESS","type":"TEXT","msg":"res1: org.apache.zeppelin.spark.dep.Dependency = org.apache.zeppelin.spark.dep.Dependency@7c4bd48\n"},"dateCreated":"2015-10-25T01:28:54+0000","dateStarted":"2015-10-25T02:11:17+0000","dateFinished":"2015-10-25T02:11:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:189"},{"title":"Import datasets and upload to HDFS","text":"%sh\nmkdir magellan\nwget https://www.dropbox.com/s/98yz5j6fc4qph3v/all.tsv -P magellan/ -nv\nwget https://www.dropbox.com/s/ttp3kyr9l8hzjdz/planning_neighborhoods.zip -P magellan/ -nv\nunzip magellan/planning_neighborhoods.zip -d magellan/\nhadoop fs -put magellan .\nhadoop fs -ls magellan","dateUpdated":"2015-10-25T01:57:14+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445761744630_-2051289379","id":"20151025-012904_1717377650","result":{"code":"SUCCESS","type":"TEXT","msg":"2015-10-25 01:48:20 URL:https://dl.dropboxusercontent.com/content_link/boAcNV0LO3ylxIfmKJf8kR44Jaen3rk21rDD6UzMldXp2w5B0j81ClprWSTAYskp/file [60947802/60947802] -> \"magellan/all.tsv\" [1]\n2015-10-25 01:48:21 URL:https://dl.dropboxusercontent.com/content_link/NmsiQZ6j1ASyuo4HH4Ibg2nMLgbqzsOTZmXJzQUv9Zzgg3IVaMkNzLSlEalywhme/file [163771/163771] -> \"magellan/planning_neighborhoods.zip\" [1]\nArchive:  magellan/planning_neighborhoods.zip\n  inflating: magellan/planning_neighborhoods.dbf  \n  inflating: magellan/planning_neighborhoods.shx  \n  inflating: magellan/planning_neighborhoods.shp.xml  \n  inflating: magellan/planning_neighborhoods.shp  \n  inflating: magellan/planning_neighborhoods.sbx  \n  inflating: magellan/planning_neighborhoods.sbn  \n  inflating: magellan/planning_neighborhoods.prj  \nFound 9 items\n-rw-r--r--   3 zeppelin zeppelin   60947802 2015-10-25 01:48 magellan/all.tsv\n-rw-r--r--   3 zeppelin zeppelin       1028 2015-10-25 01:48 magellan/planning_neighborhoods.dbf\n-rw-r--r--   3 zeppelin zeppelin        567 2015-10-25 01:48 magellan/planning_neighborhoods.prj\n-rw-r--r--   3 zeppelin zeppelin        516 2015-10-25 01:48 magellan/planning_neighborhoods.sbn\n-rw-r--r--   3 zeppelin zeppelin        164 2015-10-25 01:48 magellan/planning_neighborhoods.sbx\n-rw-r--r--   3 zeppelin zeppelin     214576 2015-10-25 01:48 magellan/planning_neighborhoods.shp\n-rw-r--r--   3 zeppelin zeppelin      21958 2015-10-25 01:48 magellan/planning_neighborhoods.shp.xml\n-rw-r--r--   3 zeppelin zeppelin        396 2015-10-25 01:48 magellan/planning_neighborhoods.shx\n-rw-r--r--   3 zeppelin zeppelin     163771 2015-10-25 01:48 magellan/planning_neighborhoods.zip\n"},"dateCreated":"2015-10-25T01:29:04+0000","dateStarted":"2015-10-25T01:48:09+0000","dateFinished":"2015-10-25T01:48:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:190"},{"title":"Spark imports","text":"import magellan.{Point, Polygon, PolyLine}\nimport magellan.coord.NAD83\nimport org.apache.spark.sql.magellan.MagellanContext\nimport org.apache.spark.sql.magellan.dsl.expressions._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types._","dateUpdated":"2015-10-25T02:11:43+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","title":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440092130_1110348593","id":"20151021-080812_605865139","result":{"code":"SUCCESS","type":"TEXT","msg":"import magellan.{Point, Polygon, PolyLine}\nimport magellan.coord.NAD83\nimport org.apache.spark.sql.magellan.MagellanContext\nimport org.apache.spark.sql.magellan.dsl.expressions._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types._\n"},"dateCreated":"2015-10-21T08:08:12+0000","dateStarted":"2015-10-25T02:11:43+0000","dateFinished":"2015-10-25T02:12:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:191"},{"text":"%md\nLet us create a case class to attach the schema to this Uber Dataset so we can use the DataFrame abstraction to deal with the data.","dateUpdated":"2015-10-25T02:12:09+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763497691_-1119915749","id":"20151025-015817_871979116","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Let us create a case class to attach the schema to this Uber Dataset so we can use the DataFrame abstraction to deal with the data.</p>\n"},"dateCreated":"2015-10-25T01:58:17+0000","dateStarted":"2015-10-25T02:12:09+0000","dateFinished":"2015-10-25T02:12:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:192"},{"title":"Create case class for Uber dataset","text":"case class UberRecord(tripId: String, timestamp: String, point: Point)","dateUpdated":"2015-10-25T02:12:10+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440113738_-484789699","id":"20151021-080833_1323347800","result":{"code":"SUCCESS","type":"TEXT","msg":"defined class UberRecord\n"},"dateCreated":"2015-10-21T08:08:33+0000","dateStarted":"2015-10-25T02:12:10+0000","dateFinished":"2015-10-25T02:12:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:193"},{"text":"%md\nNow we can read the dataset into a dataframe and cache the resulting dataframe.","dateUpdated":"2015-10-25T02:12:19+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763546354_1631500257","id":"20151025-015906_914671593","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Now we can read the dataset into a dataframe and cache the resulting dataframe.</p>\n"},"dateCreated":"2015-10-25T01:59:06+0000","dateStarted":"2015-10-25T02:12:19+0000","dateFinished":"2015-10-25T02:12:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:194"},{"title":"Read Uber dataset into dataframe","text":"val uber = sc.textFile(\"magellan/all.tsv\").map { line =>\nval parts = line.split(\"\\t\" )\nval tripId = parts(0)\nval timestamp = parts(1)\nval point = Point(parts(3).toDouble, parts(2).toDouble)\nUberRecord(tripId, timestamp, point)\n}.\nrepartition(100).\ntoDF().\ncache()","dateUpdated":"2015-10-25T02:13:13+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","title":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440128685_-234471406","id":"20151021-080848_729642312","result":{"code":"SUCCESS","type":"TEXT","msg":"uber: org.apache.spark.sql.DataFrame = [tripId: string, timestamp: string, point: poin]\n"},"dateCreated":"2015-10-21T08:08:48+0000","dateStarted":"2015-10-25T02:13:13+0000","dateFinished":"2015-10-25T02:13:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:195"},{"text":"%md\nThis dataset contains the trip id, the timestamp and the latitude and longitude of each point on the trip coalesced into a Point data structure.\n\nA Point is the simplest geometric data structure available in Magellan. It represents a two dimensional point, with x and y coordinates. In this case, as is standard in geospatial analysis, the x coordinate refers to the longitude and the y coordinate the latitude.\n\nSince this dataset is not interesting in itself, we need to enrich this dataset by determining which neighborhood each of these points lie in.\n\nTo do so, we will convert the neighborhood dataset into a dataframe as well, assuming the dataset has been downloaded and the path to the dataset is neighborhoods.path.\n\nThis dataset is in what is known as the [ESRI Shapefile format](https://www.esri.com/library/whitepapers/pdfs/shapefile.pdf).\n\nThis is one of the most common formats in which geospatial data is stored. Magellan has a Data Source implementation that understands how to parse ESRI Shapefiles into Shapes and Metadata.","dateUpdated":"2015-10-25T02:13:18+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763646932_-867658388","id":"20151025-020046_206115557","result":{"code":"SUCCESS","type":"HTML","msg":"<p>This dataset contains the trip id, the timestamp and the latitude and longitude of each point on the trip coalesced into a Point data structure.</p>\n<p>A Point is the simplest geometric data structure available in Magellan. It represents a two dimensional point, with x and y coordinates. In this case, as is standard in geospatial analysis, the x coordinate refers to the longitude and the y coordinate the latitude.</p>\n<p>Since this dataset is not interesting in itself, we need to enrich this dataset by determining which neighborhood each of these points lie in.</p>\n<p>To do so, we will convert the neighborhood dataset into a dataframe as well, assuming the dataset has been downloaded and the path to the dataset is neighborhoods.path.</p>\n<p>This dataset is in what is known as the <a href=\"https://www.esri.com/library/whitepapers/pdfs/shapefile.pdf\">ESRI Shapefile format</a>.</p>\n<p>This is one of the most common formats in which geospatial data is stored. Magellan has a Data Source implementation that understands how to parse ESRI Shapefiles into Shapes and Metadata.</p>\n"},"dateCreated":"2015-10-25T02:00:46+0000","dateStarted":"2015-10-25T02:13:18+0000","dateFinished":"2015-10-25T02:13:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:196"},{"title":"Create MagellanContext","text":"val magellanContext = new MagellanContext(sc)","dateUpdated":"2015-10-25T02:14:18+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440140325_-1659581332","id":"20151021-080900_1112437015","result":{"code":"SUCCESS","type":"TEXT","msg":"magellanContext: org.apache.spark.sql.magellan.MagellanContext = org.apache.spark.sql.magellan.MagellanContext@b79fffa\n"},"dateCreated":"2015-10-21T08:09:00+0000","dateStarted":"2015-10-25T02:14:18+0000","dateFinished":"2015-10-25T02:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:197"},{"text":"%md\nThere are two columns in this DataFrame: a shape representing the neighborhood which happens to be polygonal, and metadata which is a map of String keys and String values.\n\nMagellan has a Polygon data structure to capture the spatial geometry of a Polygon. A Polygon in Magellan stands for a Polygonal object with zero or more holes.\nMap columns can be exploded into their keys and values to yield the following dataframe:","dateUpdated":"2015-10-25T02:14:24+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763750246_580257348","id":"20151025-020230_2044689047","result":{"code":"SUCCESS","type":"HTML","msg":"<p>There are two columns in this DataFrame: a shape representing the neighborhood which happens to be polygonal, and metadata which is a map of String keys and String values.</p>\n<p>Magellan has a Polygon data structure to capture the spatial geometry of a Polygon. A Polygon in Magellan stands for a Polygonal object with zero or more holes.\n<br  />Map columns can be exploded into their keys and values to yield the following dataframe:</p>\n"},"dateCreated":"2015-10-25T02:02:30+0000","dateStarted":"2015-10-25T02:14:24+0000","dateFinished":"2015-10-25T02:14:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:198"},{"title":"Load neighborhoods dataset into DataFrame representing each one as polygon and metadata","text":"val neighborhoods = magellanContext.read.format(\"magellan\").\nload(\"magellan\").\nselect($\"polygon\", $\"metadata\").\ncache()","dateUpdated":"2015-10-25T02:19:17+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","title":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440171544_1945192409","id":"20151021-080931_281898278","result":{"code":"SUCCESS","type":"TEXT","msg":"neighborhoods: org.apache.spark.sql.DataFrame = [polygon: pol, metadata: map<string,string>]\n"},"dateCreated":"2015-10-21T08:09:31+0000","dateStarted":"2015-10-25T02:19:17+0000","dateFinished":"2015-10-25T02:19:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:199"},{"title":"View sample of neighbourhood DataFrame","text":"neighborhoods.select(explode($\"metadata\").as(Seq(\"k\", \"v\"))).show(5)","dateUpdated":"2015-10-25T02:20:39+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440185987_-804977404","id":"20151021-080945_1330980387","result":{"code":"SUCCESS","type":"TEXT","msg":"+----------+--------------------+\n|         k|                   v|\n+----------+--------------------+\n|neighborho|Twin Peaks       ...|\n|neighborho|Pacific Heights  ...|\n|neighborho|Visitacion Valley...|\n|neighborho|Potrero Hill     ...|\n|neighborho|Crocker Amazon   ...|\n+----------+--------------------+\n\n"},"dateCreated":"2015-10-21T08:09:45+0000","dateStarted":"2015-10-25T02:20:39+0000","dateFinished":"2015-10-25T02:20:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:200"},{"text":"%md\nNow we are getting somewhere: we are able to parse the San Francisco neighborhood dataset, extract its metadata as well as the polygon shapes that represent each neighborhood. \nThe natural next step is to join this dataset with the uber dataset so that each point on the uber trip can be associated with its corresponding neighborhood.  \n\nHere we run into an important spatial query: How do we compute whether a given point (uber location) lies within a given polygon (or neighborhood) ?\n\nMagellan implements th as well as other spatial operators like intersects, intersection, contains, covers etc making it easy to use.\nIn Magellan, to join the Uber dataset with the San Francisco neighborhood dataset, you would issue the following Spark SQL query:","dateUpdated":"2015-10-25T02:21:01+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763816159_-205876600","id":"20151025-020336_1732297633","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Now we are getting somewhere: we are able to parse the San Francisco neighborhood dataset, extract its metadata as well as the polygon shapes that represent each neighborhood.\n<br  />The natural next step is to join this dataset with the uber dataset so that each point on the uber trip can be associated with its corresponding neighborhood.</p>\n<p>Here we run into an important spatial query: How do we compute whether a given point (uber location) lies within a given polygon (or neighborhood) ?</p>\n<p>Magellan implements th as well as other spatial operators like intersects, intersection, contains, covers etc making it easy to use.\n<br  />In Magellan, to join the Uber dataset with the San Francisco neighborhood dataset, you would issue the following Spark SQL query:</p>\n"},"dateCreated":"2015-10-25T02:03:36+0000","dateStarted":"2015-10-25T02:20:59+0000","dateFinished":"2015-10-25T02:20:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:201"},{"title":"Map Uber Trips to neighborhoods","text":"neighborhoods.\njoin(uber).\nwhere($\"point\" within $\"polygon\").\nselect($\"tripId\", $\"timestamp\", explode($\"metadata\").as(Seq(\"k\", \"v\"))).\nwithColumnRenamed(\"v\", \"neighborhood\").\ndrop(\"k\").\nshow(5)","dateUpdated":"2015-10-25T02:26:54+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440209587_1902362688","id":"20151021-081009_570116241","result":{"code":"SUCCESS","type":"TEXT","msg":"+------+---------+------------+\n|tripId|timestamp|neighborhood|\n+------+---------+------------+\n+------+---------+------------+\n\n"},"dateCreated":"2015-10-21T08:10:09+0000","dateStarted":"2015-10-25T02:22:04+0000","dateFinished":"2015-10-25T02:22:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:202"},{"text":"%md\nThis is interesting: According to our calculation, the GPS coordinates representing the Uber dataset do not fall in any of the San Francisco neighborhoods. How can this be?\n\nThis is a good point to pause and think about coordinate systems. We have been using GPS coordinates for the Uber dataset, but haven’t verified the coordinate system that the San Francisco neighborhood dataset has been encoded in.\n\nIt turns out that most datasets published by the US governmental agencies use what is called State Plane coordinates.\n\nMagellan supports translating between different coordinate systems by implementing a transformer interface which takes in Points and outputs Points.\n\nThis covers all conformal transformations which is the set of all transformations that preserve angles.\nIn particular, to translate between WGS84, the GPS standard coordinate system used in the Uber dataset, and NAD83 Zone 403 (state plane), we can use the following in built transformer:","dateUpdated":"2015-10-25T02:04:17+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763847366_-916077097","id":"20151025-020407_503661891","result":{"code":"SUCCESS","type":"HTML","msg":"<p>This is interesting: According to our calculation, the GPS coordinates representing the Uber dataset do not fall in any of the San Francisco neighborhoods. How can this be?</p>\n<p>This is a good point to pause and think about coordinate systems. We have been using GPS coordinates for the Uber dataset, but haven’t verified the coordinate system that the San Francisco neighborhood dataset has been encoded in.</p>\n<p>It turns out that most datasets published by the US governmental agencies use what is called State Plane coordinates.</p>\n<p>Magellan supports translating between different coordinate systems by implementing a transformer interface which takes in Points and outputs Points.</p>\n<p>This covers all conformal transformations which is the set of all transformations that preserve angles.\n<br  />In particular, to translate between WGS84, the GPS standard coordinate system used in the Uber dataset, and NAD83 Zone 403 (state plane), we can use the following in built transformer:</p>\n"},"dateCreated":"2015-10-25T02:04:07+0000","dateStarted":"2015-10-25T02:04:13+0000","dateFinished":"2015-10-25T02:04:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:203"},{"title":"Create Translator between Uber and Neighborhood coordinate systems","text":"val transformer: Point => Point = (point: Point) => {\nval from = new NAD83(Map(\"zone\" -> 403)).from()\nval p = point.transform(from)\nnew Point(3.28084 * p.x, 3.28084 * p.y)\n}","dateUpdated":"2015-10-25T02:23:41+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440220764_-922078987","id":"20151021-081020_167250911","result":{"code":"SUCCESS","type":"TEXT","msg":"transformer: magellan.Point => magellan.Point = <function1>\n"},"dateCreated":"2015-10-21T08:10:20+0000","dateStarted":"2015-10-25T02:23:41+0000","dateFinished":"2015-10-25T02:23:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:204"},{"text":"%md\nHere we have defined a new transformer that applies the NAD83 transformation for Zone 403 (Northern California) and further scales the points to have units in feet instead of meters.\nThis allows us to enhance the uber dataset by adding a new column, the scaled column representing the coordinates in the NAD83 State Plane Coordinate System:","dateUpdated":"2015-10-25T02:04:48+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763881843_-719223578","id":"20151025-020441_781592444","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Here we have defined a new transformer that applies the NAD83 transformation for Zone 403 (Northern California) and further scales the points to have units in feet instead of meters.\n<br  />This allows us to enhance the uber dataset by adding a new column, the scaled column representing the coordinates in the NAD83 State Plane Coordinate System:</p>\n"},"dateCreated":"2015-10-25T02:04:41+0000","dateStarted":"2015-10-25T02:04:46+0000","dateFinished":"2015-10-25T02:04:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:205"},{"title":"Add translated Coordinates column to Uber dataFrame","text":"val uberTransformed = uber.\nwithColumn(\"nad83\", $\"point\".transform(transformer)).\ncache()","dateUpdated":"2015-10-25T02:24:58+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440242411_2145954714","id":"20151021-081042_1983405488","result":{"code":"SUCCESS","type":"TEXT","msg":"uberTransformed: org.apache.spark.sql.DataFrame = [tripId: string, timestamp: string, point: poin, nad83: poin]\n"},"dateCreated":"2015-10-21T08:10:42+0000","dateStarted":"2015-10-25T02:24:58+0000","dateFinished":"2015-10-25T02:24:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:206"},{"text":"%md\nNow we are ready to perform the join again:","dateUpdated":"2015-10-25T02:05:10+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763903868_2114113295","id":"20151025-020503_1617259756","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Now we are ready to perform the join again:</p>\n"},"dateCreated":"2015-10-25T02:05:03+0000","dateStarted":"2015-10-25T02:05:07+0000","dateFinished":"2015-10-25T02:05:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207"},{"title":"Map Uber Trips To Neighborhoods","text":"val joined = neighborhoods.\njoin(uberTransformed).\nwhere($\"nad83\" within $\"polygon\").\nselect($\"tripId\", $\"timestamp\", explode($\"metadata\").as(Seq(\"k\", \"v\"))).\nwithColumnRenamed(\"v\", \"neighborhood\").\ndrop(\"k\").\ncache()","dateUpdated":"2015-10-25T02:26:46+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440253040_-455332599","id":"20151021-081053_1128907682","result":{"code":"SUCCESS","type":"TEXT","msg":"joined: org.apache.spark.sql.DataFrame = [tripId: string, timestamp: string, neighborhood: string]\n"},"dateCreated":"2015-10-21T08:10:53+0000","dateStarted":"2015-10-25T02:25:04+0000","dateFinished":"2015-10-25T02:25:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:208"},{"text":"joined.show(5)","dateUpdated":"2015-10-25T02:25:13+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440262325_976100231","id":"20151021-081102_231185976","result":{"code":"SUCCESS","type":"TEXT","msg":"+------+--------------------+--------------------+\n|tripId|           timestamp|        neighborhood|\n+------+--------------------+--------------------+\n| 12478|2007-01-05T04:55:...|Haight Ashbury   ...|\n| 12483|2007-01-07T07:37:...|Mission          ...|\n| 12484|2007-01-02T04:02:...|South of Market  ...|\n| 12487|2007-01-07T04:26:...|Downtown/Civic Ce...|\n| 12489|2007-01-07T03:00:...|Castro/Upper Mark...|\n+------+--------------------+--------------------+\n\n"},"dateCreated":"2015-10-21T08:11:02+0000","dateStarted":"2015-10-25T02:25:13+0000","dateFinished":"2015-10-25T02:25:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:209"},{"text":"%md\nOk, this looks much more reasonable!\nOne interesting question we are now ready to ask is: What are the top few neighborhoods where most Uber trips pass through?","dateUpdated":"2015-10-25T02:05:32+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445763926053_383158642","id":"20151025-020526_1159970756","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Ok, this looks much more reasonable!\n<br  />One interesting question we are now ready to ask is: What are the top few neighborhoods where most Uber trips pass through?</p>\n"},"dateCreated":"2015-10-25T02:05:26+0000","dateStarted":"2015-10-25T02:05:29+0000","dateFinished":"2015-10-25T02:05:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:210"},{"title":"Show top neighborhoods where most Uber trips pass through","text":"joined.\ngroupBy($\"neighborhood\").\nagg(countDistinct(\"tripId\").\nas(\"trips\")).\norderBy(col(\"trips\").desc).\nshow(5)","dateUpdated":"2015-10-25T02:28:04+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"title":true,"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440273534_-1857575419","id":"20151021-081113_1220870628","result":{"code":"SUCCESS","type":"TEXT","msg":"+--------------------+-----+\n|        neighborhood|trips|\n+--------------------+-----+\n|South of Market  ...| 9891|\n|Western Addition ...| 6794|\n|Downtown/Civic Ce...| 6697|\n|Financial Distric...| 6038|\n|Mission          ...| 5620|\n+--------------------+-----+\n\n"},"dateCreated":"2015-10-21T08:11:13+0000","dateStarted":"2015-10-25T02:28:04+0000","dateFinished":"2015-10-25T02:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:211"},{"text":"%md\nThere are about 24664 trips for which we have neighborhood information, out of which close to 40% of the trips involve SOMA. \nNow if you are an Uber driver, you may just want to hang out around SOMA.","dateUpdated":"2015-10-25T02:28:22+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445440285513_-845270414","id":"20151021-081125_2064619705","result":{"code":"SUCCESS","type":"HTML","msg":"<p>There are about 24664 trips for which we have neighborhood information, out of which close to 40% of the trips involve SOMA.\n<br  />Now if you are an Uber driver, you may just want to hang out around SOMA.</p>\n"},"dateCreated":"2015-10-21T08:11:25+0000","dateStarted":"2015-10-25T02:28:20+0000","dateFinished":"2015-10-25T02:28:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:212"},{"text":"%md\nAs we see, once we add geospatial context to the Uber dataset, we end up with a fascinating array of questions we can ask about the nature of Uber trips in the city of San Francisco.\n\n### Summary\n\nIn this blog post, we have shown how to use Magellan to perform geospatial analysis on Spark.\n\nHopefully this short introduction has demonstrated how easy and elegant it is to incorporate geospatial context in your applications using Magellan.\n\nIn the future, we will go under the hood to examine how Magellan leverages Spark SQL, Data Frames and Catalyst to provide elegant and simple user APIs while ensuring that spatial queries can execute efficiently.\n","dateUpdated":"2015-10-25T02:28:33+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445764101016_1061302910","id":"20151025-020821_915639433","result":{"code":"SUCCESS","type":"HTML","msg":"<p>As we see, once we add geospatial context to the Uber dataset, we end up with a fascinating array of questions we can ask about the nature of Uber trips in the city of San Francisco.</p>\n<h3>Summary</h3>\n<p>In this blog post, we have shown how to use Magellan to perform geospatial analysis on Spark.</p>\n<p>Hopefully this short introduction has demonstrated how easy and elegant it is to incorporate geospatial context in your applications using Magellan.</p>\n<p>In the future, we will go under the hood to examine how Magellan leverages Spark SQL, Data Frames and Catalyst to provide elegant and simple user APIs while ensuring that spatial queries can execute efficiently.</p>\n"},"dateCreated":"2015-10-25T02:08:21+0000","dateStarted":"2015-10-25T02:28:33+0000","dateFinished":"2015-10-25T02:28:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:213"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1445764171206_-151886992","id":"20151025-020931_300901096","dateCreated":"2015-10-25T02:09:31+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:214"}],"name":"Demos / Magellan / Geospatial Analytics","id":"2B4TWGC8M","angularObjects":{},"config":{"looknfeel":"default"},"info":{}}